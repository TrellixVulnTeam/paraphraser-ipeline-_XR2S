{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xYEG7vnM4YL"
   },
   "source": [
    "# Machine-made Datasets\n",
    "Authors: Ruslan Mammadov\n",
    "\n",
    "Copyright (C) 2021 Ruslan Mammadov and DynaGroup i.T. GmbH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 230,
     "status": "ok",
     "timestamp": 1633778033058,
     "user": {
      "displayName": "Ruslan Mammadov",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03871087646573601592"
     },
     "user_tz": -120
    },
    "id": "KR37lxwSwa9r",
    "outputId": "6303daf2-9fc0-4338-8c88-61f41a18be04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HVdHSOvbj0Xy"
   },
   "source": [
    "# PPDB Dataset\n",
    "\n",
    "http://paraphrase.org\n",
    "\n",
    "TLDR:\n",
    "1. This dataset was created by machine, not by humans => huge, but not always acurate\n",
    "2. It does not contain sentences, but the syntactic \"rules\"\n",
    "3. It can not be used for training, but to augment the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YN6iYsMVqlyN"
   },
   "source": [
    "Long version:\n",
    "1. Dataset was created automatically using pivoting method (find 2 phrases translated to the same foreign phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 97922,
     "status": "ok",
     "timestamp": 1633775163620,
     "user": {
      "displayName": "Ruslan Mammadov",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03871087646573601592"
     },
     "user_tz": -120
    },
    "id": "NgXwTvU9wsc1",
    "outputId": "bfe5f00f-7bce-420a-f42d-9877dabf4bb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the small (!) version: 4551746\n"
     ]
    }
   ],
   "source": [
    "# Let's load small version with the words with the best score!\n",
    "with open(\"drive/MyDrive/Paraphrasing API/datasets/Machine Made Datasets/ppdb-2.0-s-all\", \"r\") as file:\n",
    "  lines = file.readlines()\n",
    "ppdb_small_version = [item.split(\" ||| \") for item in lines]\n",
    "del lines\n",
    "print(f\"Size of the small (!) version: {len(ppdb_small_version)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xQW051TrRbt"
   },
   "source": [
    "2. It contains syntaxis rules\n",
    "  \n",
    "  It uses part-of-speech tags like VP, NP, etc. The whole list: https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 205,
     "status": "ok",
     "timestamp": 1633775539914,
     "user": {
      "displayName": "Ruslan Mammadov",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03871087646573601592"
     },
     "user_tz": -120
    },
    "id": "GqPIX6ADnEvo",
    "outputId": "e6c93604-4abc-48a4-e136-20663ac63e0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[VP]',\n",
       " 'to address [NP/NP,1] [NP,2]',\n",
       " 'deal with [NP/NP,1] [NP,2]',\n",
       " 'PPDB2.0Score=5.66727 PPDB1.0Score=5.285380 -logp(LHS|e1)=0.30792 -logp(LHS|e2)=0.23248 -logp(e1|LHS)=11.25391 -logp(e1|e2)=2.55238 -logp(e1|e2,LHS)=2.50087 -logp(e2|LHS)=11.75635 -logp(e2|e1)=2.73300 -logp(e2|e1,LHS)=2.69047 AGigaSim=0.61523 Abstract=0 Adjacent=1 CharCountDiff=-1 CharLogCR=-0.08701 ContainsX=0 Equivalence=0.146875 Exclusion=0.154067 GlueRule=0 GoogleNgramSim=0 Identity=0 Independent=0.162137 Lex(e1|e2)=59.95702 Lex(e2|e1)=59.95702 Lexical=0 LogCount=3.98898 MVLSASim=NA Monotonic=1 OtherRelated=0.009753 PhrasePenalty=1 RarityPenalty=0 ForwardEntailment=0.527168 SourceTerminalsButNoTarget=0 SourceWords=2 TargetTerminalsButNoSource=0 TargetWords=2 UnalignedSource=1 UnalignedTarget=1 WordCountDiff=0 WordLenDiff=-0.50000 WordLogCR=0',\n",
       " '0-0 1-0 1-1 2-2 3-3',\n",
       " 'ForwardEntailment\\n']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example\n",
    "# 1. The word hast to be VP - verbal phrase,.\n",
    "# 2. NP/NP - Placeholder for \"Noun phrase without Noun phrase\"\n",
    "# 3. Score probability and other features.\n",
    "# 4. 0-0, 0-1, Positions how can you replace it\n",
    "# 5. Type of relations: ForwardEntailment - means that right side always mean left side, but left side \n",
    "# may not mean the right side\n",
    "ppdb_small_version[2000000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-XTU5HiTkxHK"
   },
   "source": [
    "3. There are two types of rules:\n",
    "   1. Lexical & Phrasal (single/multiword to single/multiword): \n",
    "      \n",
    "      Example: http://paraphrase.org/#/search?q=complete&filter=%5BVP%5D&lang=en\n",
    "   2. Syntactic (paraphrase rules containing non-terminal symbols (NP, VP, etc.))\n",
    "      \n",
    "      Example: http://paraphrase.org/#/search?q=in%20respect%20to&filter=&lang=en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhl6S3ZyrqVP"
   },
   "source": [
    "4. Not all rules are good:\n",
    "\n",
    "  However, you can always choose a rule with better score: http://paraphrase.org/#/search?q=reaffirmed&filter=&lang=en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1633777016429,
     "user": {
      "displayName": "Ruslan Mammadov",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03871087646573601592"
     },
     "user_tz": -120
    },
    "id": "AVnJeTxaigiW",
    "outputId": "f00c887b-442d-4fbe-db57-b520bcc1ceea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[VB]',\n",
       " 'reaffirmed',\n",
       " 'reiterate',\n",
       " 'PPDB2.0Score=4.18659 PPDB1.0Score=9.814040 -logp(LHS|e1)=5.70920 -logp(LHS|e2)=0.29931 -logp(e1|LHS)=13.76320 -logp(e1|e2)=4.90406 -logp(e1|e2,LHS)=7.54041 -logp(e2|LHS)=8.35922 -logp(e2|e1)=4.90998 -logp(e2|e1,LHS)=2.13643 AGigaSim=0.54532 Abstract=0 Adjacent=0 CharCountDiff=-1 CharLogCR=-0.10536 ContainsX=0 Equivalence=0.405977 Exclusion=0.001277 GlueRule=0 GoogleNgramSim=0 Identity=0 Independent=0.349517 Lex(e1|e2)=62.39058 Lex(e2|e1)=62.39058 Lexical=1 LogCount=1.38629 MVLSASim=NA Monotonic=1 OtherRelated=0.173768 PhrasePenalty=1 RarityPenalty=0 ReverseEntailment=0.069461 SourceTerminalsButNoTarget=0 SourceWords=1 TargetComplexity=0.99694 TargetFormality=1.00000 TargetTerminalsButNoSource=0 TargetWords=1 UnalignedSource=0 UnalignedTarget=0 WordCountDiff=0 WordLenDiff=-1.00000 WordLogCR=0',\n",
       " '0-0',\n",
       " 'Equivalence\\n']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Really equivalence?\n",
    "ppdb_small_version[3000] # VB - Verb, base form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OsGT3tqctG3T"
   },
   "source": [
    "### Conclusion\n",
    "1. You can not use it for training, it is not sentences\n",
    "2. You can not use it for paraphrasing alone, it is not powerful enough.\n",
    "3. It is used to augment the data (paraphrasic augmentation):\n",
    "  1. For human-made datasets, to increase the size by alternating samples using random rules with high scores \n",
    "    1. https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00380/100783/Iterative-Paraphrastic-Augmentation-with\n",
    "    2. [NLPAug Library](https://github.com/makcedward/nlpaug) uses PPDB\n",
    "  2. For machine-made datasets, you can increase the diversity between input and output\n",
    "    1. Next sections\n",
    "    2. Also https://aclanthology.org/N19-1090/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ISk-O_tGvo4b"
   },
   "source": [
    "# Machine made datasets, improved by PPDB\n",
    "\n",
    "Two kind of datasets:\n",
    "1. Human made are small and good\n",
    "2. Machine made are gigantic and bad\n",
    "\n",
    "## Parabank 2\n",
    "https://nlp.jhu.edu/parabank/ -> ParaBank v2.0\n",
    "\n",
    "TLDR:\n",
    "1. The best machine made dataset I have found, we can use if we want to train a big model (100 millions samples), but for fine-tuning use human made datasets (better language, more accurate)\n",
    "\n",
    "Long version:\n",
    "1. Sentence to sentence\n",
    "2. Machine made => a lot of samples (100 millions), but worse quality\n",
    "3. Quite new, 2019, based on previous machine-made dataset with lower diversity\n",
    "3. The authors concentrated on better diversity\n",
    "4. Was created by translating to Czech and back\n",
    "5. Improved the diversity by applying PPDB rules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2425,
     "status": "ok",
     "timestamp": 1633779433782,
     "user": {
      "displayName": "Ruslan Mammadov",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03871087646573601592"
     },
     "user_tz": -120
    },
    "id": "rMNRkTGptMfO",
    "outputId": "423db4b4-8b15-4b14-952e-7b1c562bc2f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10400667it [02:36, 66283.90it/s] \n"
     ]
    }
   ],
   "source": [
    "reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 169589,
     "status": "ok",
     "timestamp": 1633780461603,
     "user": {
      "displayName": "Ruslan Mammadov",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03871087646573601592"
     },
     "user_tz": -120
    },
    "id": "VETvbkqAuBm-",
    "outputId": "50303369-2482-45e3-dbe4-f7613279be4e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10405002it [02:49, 61531.72it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of parabank2 sampled every 1000 line is 10406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's load parabank2.\n",
    "from tqdm import tqdm\n",
    "\n",
    "take_first_n = 10000\n",
    "parabank2_highest_scores = []\n",
    "\n",
    "read_every_n_line = 1000\n",
    "parabank2 = []\n",
    "\n",
    "with open(\"drive/MyDrive/Paraphrasing API/datasets/Machine Made Datasets/parabank2.tsv\", \"r\") as file:\n",
    "  for i, line in tqdm(enumerate(file)):\n",
    "    if i < take_first_n:\n",
    "      parabank2_highest_scores.append(line.split(\"\\t\"))\n",
    "    if i % read_every_n_line:\n",
    "      continue\n",
    "    parabank2.append(line.split(\"\\t\"))\n",
    "print(f\"Size of parabank2 sampled every {read_every_n_line} lines is {len(parabank2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F2NTFT9U6Z5n"
   },
   "source": [
    "Let's look at the samples with best scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 202,
     "status": "ok",
     "timestamp": 1633780866643,
     "user": {
      "displayName": "Ruslan Mammadov",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03871087646573601592"
     },
     "user_tz": -120
    },
    "id": "A2ZuB5mi6edw",
    "outputId": "b6a45c61-87cc-46fa-850e-aacf1dbd6acc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.9286716938412872',\n",
       " '2002 IIHF World U18 Championships',\n",
       " '2002 World Ice Hockey Championships',\n",
       " '2002 World Ice Hockey Championship in 18 years',\n",
       " '2002 IIHF World Cup',\n",
       " '2002 World Ice Hockey Championship (IIHF)',\n",
       " '2002 World Iced Hockey Championship Championships\\n']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parabank2_highest_scores[10]  # First 1000 samples are names of organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 203,
     "status": "ok",
     "timestamp": 1633780656989,
     "user": {
      "displayName": "Ruslan Mammadov",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03871087646573601592"
     },
     "user_tz": -120
    },
    "id": "vV8lJjaB6kbU",
    "outputId": "39e80137-b51b-48fa-8c9d-4b509dde6408"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.8904752232974726',\n",
       " 'Cooperation with the European Centre for the Development of Vocational Training (Cedefop)',\n",
       " 'Working with European Centre for the Developing of Vocational Teaching (Cedefop)',\n",
       " 'Cooperation with the European Cedefop (Cedefop)',\n",
       " 'Co-operation with Cedefop European Centre for the Development of Vocal Training (CEDEFOP)',\n",
       " 'Work with the European Center on Vocal Training Development (Cedefop)',\n",
       " 'Cooperation with Cedefop (European Center for the Developing of Vocational Education)\\n']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parabank2_highest_scores[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 191,
     "status": "ok",
     "timestamp": 1633780729280,
     "user": {
      "displayName": "Ruslan Mammadov",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03871087646573601592"
     },
     "user_tz": -120
    },
    "id": "JxQg41vWwkmz",
    "outputId": "7b692218-6097-4e25-a19a-a2eca977bfdc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.8089646975664998',\n",
       " 'Six to eight men.',\n",
       " '6 or 8 men.',\n",
       " '6-8 men.',\n",
       " 'Between 6 and 8 men.',\n",
       " '6 to Eight men.',\n",
       " \"It's 6 to 8 men\\n\"]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parabank2_highest_scores[-5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bXKPgWq57MGg"
   },
   "source": [
    "Let's look at samples with low score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 209,
     "status": "ok",
     "timestamp": 1633780840178,
     "user": {
      "displayName": "Ruslan Mammadov",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03871087646573601592"
     },
     "user_tz": -120
    },
    "id": "5tKCTSLKypVF",
    "outputId": "50047130-aaf5-45c9-e2cf-645dfd4fe1fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.39455371037160114',\n",
       " '- The inspection manual has been issued to all Polish fisheries inspectors.',\n",
       " '- A guide on inspections was issued to all Polish fisheries inspectors.',\n",
       " '- All Polish fish inspectors have been provided with a manual on inspections.',\n",
       " '- All Polish fishing inspectors have been given a Manual on inspections.',\n",
       " '- All Polish fisheries inspectors have been issued with an inspection manual.',\n",
       " '- All Polian fisheries inspectors have been issued a manual concerning inspections.\\n']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parabank2[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 201,
     "status": "ok",
     "timestamp": 1633780846642,
     "user": {
      "displayName": "Ruslan Mammadov",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03871087646573601592"
     },
     "user_tz": -120
    },
    "id": "Okwyvc7fzANt",
    "outputId": "d21eb131-a9bd-44b4-c556-1d700f31a8eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.08950149051868009',\n",
       " \"She's got a cousin in the military and she's kind of anxious about it.\",\n",
       " \"He has cousins in the Army, and he's a little worried.\",\n",
       " \"She has a cousin in the Army, And she's just a little bit concerned about it.\",\n",
       " \"He has a cousin in the Army who's a little worried.\",\n",
       " 'He has a cousin in his army and a little worried about that.',\n",
       " \"He's got an army cousin and he's kind of concerned.\\n\"]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parabank2[10000] # Wrong He != She."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUNeOvkwpq3u"
   },
   "source": [
    "## Conclusion\n",
    "The dataset can be used \n",
    "1. To train big models that require a lot of data, before finetuning\n",
    "2. To teach models some basic tricks how to do paraphrasing\n",
    "\n",
    "The model should **not** be used:\n",
    "1. For finetuning.\n",
    "2. As the only training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h7CWcuDH7jC-"
   },
   "source": [
    "#### Another machine made datasets\n",
    "1. Parabank - Previous version, less diversity.\n",
    "2. ParaNMT - predecessor, just translation to Czech and back, no PPDB => even less diversity than in Parabank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6t4bTjccZpZQ"
   },
   "source": [
    "# Some other datasets that were not at the list\n",
    "\n",
    "https://opendata.stackexchange.com/questions/6094/paraphrase-data-sets\n",
    "\n",
    "TLDR:\n",
    "1. We can use many labeled semantic evaluations datasets by just filtering out non-paraprases.\n",
    "\n",
    "Long version:\n",
    "\n",
    "Multiple semantic evaluations datasets\n",
    "1. They mostly contain labeled samples of \n",
    "  1. Paraphrases vs non-paraphrases, \n",
    "  2. Or entailment vs contradictions vs neutral phrases\n",
    "2. But we can filter out non-paraphrases\n",
    "\n",
    "\n",
    "1. [Paws](https://github.com/google-research-datasets/paws): Google made, sentence-sentence, 108,463 human-labeled and 656k noisily labeled pairs of paraphreases and non paraphrases.\n",
    "2. [Microsoft Research Paraphrase Corpus](https://www.microsoft.com/en-us/download/details.aspx?id=52398&from=http%3A%2F%2Fresearch.microsoft.com%2Fen-us%2Fdownloads%2F607d14d9-20cd-47e3-85bc-a2f65cd28042%2F): 5800 pairs of labeled paraphrase and non-paraphrase sentences\n",
    "3. [SNLI](https://nlp.stanford.edu/projects/snli/): 570k sentence pairs of entailment, contradictions and neutral phrases \n",
    "3. SNIPS Alexa commands; MSRP Frames; GYAFC Dataset - have not looked into that\n",
    "4. **Other datasets for semantic evaluations challenges.**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k6RiAoHGmhCp"
   },
   "source": [
    "# Evaluation scores\n",
    "\n",
    "### Scores based on input-output comparison\n",
    "\n",
    "https://aclanthology.org/K19-1005/\n",
    "\n",
    "TLDR: Look at the cool metrics in the next cell.\n",
    "\n",
    "Long version: Here, I will concentrate on scores based on **input <-> output comparison**, not based on references (which we should use too). Advantages:\n",
    "\n",
    "1. We can not expect the output to be always similar to reference => reference based metrics may not be always indicative\n",
    "2. Similarity to the reference depends on data the model trained on => hard to compare models trained on different datasets\n",
    "\n",
    "### Two kinds of such scores\n",
    "We want to change the words but keep the meaning. So, we should have 2 kinds of scores:\n",
    "1. Diversity between output and input\n",
    "  1. Three kinds: Lexical, phrasal, and Syntactical\n",
    "2. Adequacy, or semantic similarity (i.e. how similar is meaning)\n",
    "3. Fluency (Is the paraphrase fluent English?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPB9mm1cr6qT"
   },
   "source": [
    "## Paraphrasic divesity scores\n",
    "1. BLEU score, but \n",
    "  1. Between output and input, **not reference**.\n",
    "  2. We are interested in diversity => Higher Bleu = **worse** diversity => worse results\n",
    "  3. Measures \"Phrasal diversity\"\n",
    "2. ∩/∪ or Intersection/Union score\n",
    "  1. Number of shared words / number of all words.\n",
    "  2. Higher score = worse diversity\n",
    "  3. Measures \"lexical diversity\"\n",
    "3. Tree ED or Tree edit distance\n",
    "  1. Syntactic parse sentences into tree\n",
    "  2. Compute tree distance, i.e. how different are the tree.\n",
    "  3. Used in https://aclanthology.org/K19-1005/ and in some other papers\n",
    "  4. Hard to find ready to use implementation\n",
    "  5. Easy to find implmentations for syntactic parse and tree distance.\n",
    "  6. (Or we can use nltk's edit_distance, but it is a little bit different)\n",
    "  7. Measures \"syntactic diversity\"\n",
    "\n",
    "Example for syntactic tree:\n",
    "![Example-of-constituent-syntactic-parse-tree.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ow78EeNX02P1"
   },
   "source": [
    "##  Semantic similarity scores\n",
    "1. Compare sentence embeddings\n",
    "  1. BERT\n",
    "  2. BERT finetuned by paraphrases datasets\n",
    "    1. Example: https://zenodo.org/record/3524708#.YWKuExBBxQI\n",
    "  2. T5-11B, XLNet, ALBERT, RoBERTa (improvements on/over BERT): \n",
    "  https://arxiv.org/pdf/2004.13820.pdf\n",
    "2. Semantic similiary trained models?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9tptzlcuisy"
   },
   "source": [
    "# Fluency\n",
    "1. Sorry, did not have time to investigate :(. Let's do it next week :)\n",
    "2. Perplexity?\n",
    "3. Grammar score?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z8WnUXUak4k5"
   },
   "source": [
    "# Surprise\n",
    "There are already many paraphrasers online:\n",
    "1. [\"10 Best Paraphrasing Tools (Free & Paid) – 2021\"](https://rigorousthemes.com/blog/best-paraphrasing-tools-free-paid/)\n",
    "\n",
    "Completely free:\n",
    "2. https://www.prepostseo.com/paraphrasing-tool\n",
    "3. https://www.editpad.org/tool/paraphrasing-tool\n",
    "4. https://www.paraphraser.io/\n",
    "\n",
    "Partly free, which also means that they make buisness with that => resources & full time workers\n",
    "5. https://quillbot.com/\n",
    "6. https://www.wordtune.com/\n",
    "\n",
    "And \n",
    "7. 1000s other\n",
    "\n",
    "What is our task then? Use state of the art techniques? That is what https://www.prepostseo.com/paraphrasing-tool did, and they do not even show Git account or says their names..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GT0-ZhpwB5Rt"
   },
   "source": [
    "# General Approach\n",
    "1. Use all datasets and evaluation metrics that we can use\n",
    "  1. One dataset can be used only for evaluation\n",
    "2. Use several models\n",
    "  1. Test all the models, find out which performs best according to which criterias\n",
    "3. As baseline\n",
    "  1. Pivoting methods (translate to foreign and back)\n",
    "  2. Online paraphrasers found in internet (we should somehow beat them in order to be valid)\n",
    "  3. Some already trained paraphrasers\n",
    "4. Train GPT-3 as reference model\n",
    "  1. We should be able to get access to GPT-3 for two months\n",
    "  2. If our model will have the same score as GPT-3, jobe done, we are amazing\n",
    "  3. If not, we can use GPT-3 to create more samples for our model\n",
    "  4. We would know what is the best score we can achieve\n",
    "5. Investigate other models:\n",
    "  1. Performance on our evaluation metrics, architecture, +/-, etc. The models are:\n",
    "  2. 38 paraphrase models listed [here on huggingface](https://huggingface.co/models?pipeline_tag=text2text-generation&search=paraphrase) \n",
    "  3. [Parrot paraphraser](https://pythonrepo.com/repo/PrithivirajDamodaran-Parrot-python-natural-language-processing)\n",
    "  4. DNPG model Anna spoke about\n",
    "7. As one of our model: Finetune existing language generation model (GPT-2, T5, XLNet, etc.) on human-made datasets for paraphrase generation task\n",
    "  1. Why? We want the model to be able to rephrase any kind of text => The model has to speak english => \n",
    "  3. We do not have resources to teach model english from scratch => We have to use tranfer learning\n",
    "  4. Problem: it is the common approach, which means that is what many people have already done => What new can we bring to the table? Train from scratch? Not enough resourses? Not use deep learning? Probably not so effective?\n",
    "8. Fit our models (not necessarly GPT-2) every human made dataset except for one used for evaluation\n",
    "9. If it is not enough, fit it machine made datasets, but before human-made datasets\n",
    "10. Improve our models using data augmentation & finetune our models on the samples on which it fails\n",
    "  1. [Data augmentation in nlp](https://towardsdatascience.com/data-augmentation-in-nlp-2801a34dfc28)\n",
    "  2. [NLPAug Library](https://github.com/makcedward/nlpaug)\n",
    "  3. [Paraphrase Mining](https://www.sbert.net/examples/applications/paraphrase-mining/README.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3OIIDHigE1Ls"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "OsGT3tqctG3T"
   ],
   "name": "Machine-made Datasets.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
