{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "rodQ_uioZGSv",
   "metadata": {
    "executionInfo": {
     "elapsed": 61396,
     "status": "ok",
     "timestamp": 1636803183414,
     "user": {
      "displayName": "Ruslan Mammadov",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03871087646573601592"
     },
     "user_tz": -60
    },
    "id": "rodQ_uioZGSv"
   },
   "outputs": [],
   "source": [
    "!pip install wandb > /dev/null\n",
    "!pip install pytorch_lightning > /dev/null\n",
    "!pip install sacrebleu > /dev/null\n",
    "!pip install rouge > /dev/null\n",
    "!pip install datasets > /dev/null\n",
    "!pip install rouge_score > /dev/null\n",
    "!pip install bert_score > /dev/null\n",
    "!pip install torch > /dev/null\n",
    "!pip install tensorflow > /dev/null\n",
    "!pip install wget > /dev/null\n",
    "!pip install sentencepiece > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81473429",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15603,
     "status": "ok",
     "timestamp": 1636803199009,
     "user": {
      "displayName": "Ruslan Mammadov",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03871087646573601592"
     },
     "user_tz": -60
    },
    "id": "81473429",
    "outputId": "efc538a2-6fbd-4f9a-da79-65eae89a23bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "import random\n",
    "import re\n",
    "from itertools import chain\n",
    "from string import punctuation\n",
    "import wandb\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    T5ForConditionalGeneration,\n",
    "    T5Tokenizer,\n",
    "    get_linear_schedule_with_warmup\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fFWehC5kZSwx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16011,
     "status": "ok",
     "timestamp": 1636803215004,
     "user": {
      "displayName": "Ruslan Mammadov",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03871087646573601592"
     },
     "user_tz": -60
    },
    "id": "fFWehC5kZSwx",
    "outputId": "cbc6ae75-7572-457d-bf12-62c0831920f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "A0IKvC0VdY-5",
   "metadata": {
    "executionInfo": {
     "elapsed": 39506,
     "status": "ok",
     "timestamp": 1636803254501,
     "user": {
      "displayName": "Ruslan Mammadov",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03871087646573601592"
     },
     "user_tz": -60
    },
    "id": "A0IKvC0VdY-5"
   },
   "outputs": [],
   "source": [
    "!cp /content/drive/MyDrive/Paraphrasing\\ API/src . -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "mshTOxS0ZXtZ",
   "metadata": {
    "executionInfo": {
     "elapsed": 228,
     "status": "ok",
     "timestamp": 1636805265566,
     "user": {
      "displayName": "Ruslan Mammadov",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03871087646573601592"
     },
     "user_tz": -60
    },
    "id": "mshTOxS0ZXtZ"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./src\")\n",
    "\n",
    "from importlib import reload\n",
    "import metrics\n",
    "reload(metrics)\n",
    "from metrics import Metrics, BleurtModelsLinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "mqRTgdS-aeuB",
   "metadata": {
    "executionInfo": {
     "elapsed": 878,
     "status": "ok",
     "timestamp": 1636805268053,
     "user": {
      "displayName": "Ruslan Mammadov",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03871087646573601592"
     },
     "user_tz": -60
    },
    "id": "mqRTgdS-aeuB"
   },
   "outputs": [],
   "source": [
    "the_metrics = Metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ww68IcqzDH4W",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3013,
     "status": "ok",
     "timestamp": 1636803573551,
     "user": {
      "displayName": "Ruslan Mammadov",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03871087646573601592"
     },
     "user_tz": -60
    },
    "id": "ww68IcqzDH4W",
    "outputId": "1be106ea-2cd3-44df-94f5-daef531da518"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing https://storage.googleapis.com/bleurt-oss-21/BLEURT-20-D3.zip to /content/src/models/bleurt_model...\n"
     ]
    }
   ],
   "source": [
    "# Installing the smallest\n",
    "# That can take time...\n",
    "the_metrics.install_bleurt_model(BleurtModelsLinks.BLEURT_20_D3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "jmuDuiGSEbyx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17440,
     "status": "ok",
     "timestamp": 1636804910431,
     "user": {
      "displayName": "Ruslan Mammadov",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03871087646573601592"
     },
     "user_tz": -60
    },
    "id": "jmuDuiGSEbyx",
    "outputId": "a9a4e776-f18c-444c-b4e6-015d432844c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed heavy metrics with return code 0\n"
     ]
    }
   ],
   "source": [
    "# Should be several minutes if connection is good\n",
    "the_metrics.install_bert(verbose=False) # Verbose=False, otherwise the output it too big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "CElVREGYDY9Q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 118360,
     "status": "ok",
     "timestamp": 1636805391123,
     "user": {
      "displayName": "Ruslan Mammadov",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03871087646573601592"
     },
     "user_tz": -60
    },
    "id": "CElVREGYDY9Q",
    "outputId": "0597c8bc-654d-4c88-df3d-de1f9a085352"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-13 12:07:58.746465: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "Starting executing of compute_bleurt_for_every_sample.\n",
      "Execution was succesful!\n",
      "Computed heavy metrics with return code 0\n",
      "Test was successful! Output value for same strings but terrible english is 0.9610422253608704\n"
     ]
    }
   ],
   "source": [
    "# 128 sentences. Depending on model, it should take minutes/seconds on GPU. \n",
    "# On cpu, for the smaller 3 layer models, it should take several minutes.\n",
    "# If it takes much more time, use smaller model or do not use it!\n",
    "the_metrics.test_bleurt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "u0TdhviCGidz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19343,
     "status": "ok",
     "timestamp": 1636805410449,
     "user": {
      "displayName": "Ruslan Mammadov",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03871087646573601592"
     },
     "user_tz": -60
    },
    "id": "u0TdhviCGidz",
    "outputId": "51374a81-d76e-480a-99b6-e6cbc67fd52d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting executing of compute_bert_for_every_sample.\n",
      "Execution was succesful!\n",
      "Computed heavy metrics with return code 0\n",
      "Test was successful! Output value for same strings but terrible english is {'precision': 1.0000001192092896, 'recall': 1.0000001192092896, 'f1': 1.0000001192092896}\n"
     ]
    }
   ],
   "source": [
    "# 128 sentences. It should take several seconds on a good cpu, even less on GPU. \n",
    "# If it takes much more time, use GPU, or use super small sets, or do not use it.\n",
    "the_metrics.test_bert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "BdN4zeTYL3zX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 135335,
     "status": "ok",
     "timestamp": 1636807981570,
     "user": {
      "displayName": "Ruslan Mammadov",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03871087646573601592"
     },
     "user_tz": -60
    },
    "id": "BdN4zeTYL3zX",
    "outputId": "ce92daa7-555c-4c3d-f7f0-99ba1878608a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting executing of compute_bert_for_every_sample.\n",
      "Execution was succesful!\n",
      "Computed heavy metrics with return code 0\n",
      "2021-11-13 12:51:14.773519: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "Starting executing of compute_bleurt_for_every_sample.\n",
      "Execution was succesful!\n",
      "Computed heavy metrics with return code 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bert_f1': 1.0000001192092896,\n",
       " 'bert_precision': 1.0000001192092896,\n",
       " 'bert_recall': 1.0000001192092896,\n",
       " 'bleu': 1.0000000000000004,\n",
       " 'bleu_diversity': 1.0,\n",
       " 'bleu_output_input': 1.0000000000000004,\n",
       " 'bleurt': 0.9610422253608704,\n",
       " 'char_ngram_overlap': 1.0,\n",
       " 'gleu': 1.0,\n",
       " 'gleu_output_input': 1.0,\n",
       " 'intersection_over_union': 1.0,\n",
       " 'rouge1_f1': 1.0,\n",
       " 'rouge1_precision': 1.0,\n",
       " 'rouge1_recall': 1.0,\n",
       " 'rouge2_f1': 1.0,\n",
       " 'rouge2_precision': 1.0,\n",
       " 'rouge2_recall': 1.0,\n",
       " 'rougeL_f1': 1.0,\n",
       " 'rougeL_precision': 1.0,\n",
       " 'rougeL_recall': 1.0}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_data = the_metrics.get_dummy_data()\n",
    "the_metrics.compute_metrics(dummy_data, dummy_data, dummy_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808992fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "executionInfo": {
     "elapsed": 9561,
     "status": "ok",
     "timestamp": 1636641535500,
     "user": {
      "displayName": "Ruslan Mammadov",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03871087646573601592"
     },
     "user_tz": -60
    },
    "id": "808992fa",
    "outputId": "252d7d3e-b140-4098-d147-7c3b7b0c5930"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcfg2\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/cfg2/dyna_T5/runs/138qz1qo\" target=\"_blank\">scarlet-flower-9</a></strong> to <a href=\"https://wandb.ai/cfg2/dyna_T5\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# connection to wandb\n",
    "YOUR_API_KEY = 'n/a'\n",
    "os.environ[\"WANDB_API_KEY\"] = '3d4d9c4f219a83a45067149237d96e54395bffa4'\n",
    "wandb.init(project=\"dyna_T5\", entity='cfg2')\n",
    "run_name = wandb.run.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e92934",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "aborted",
     "timestamp": 1636804612038,
     "user": {
      "displayName": "Ruslan Mammadov",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03871087646573601592"
     },
     "user_tz": -60
    },
    "id": "40e92934"
   },
   "outputs": [],
   "source": [
    "# get training data\n",
    "train_path = \"data/quora_train.csv\"\n",
    "val_path = \"data/quora_eval.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc3b5ba",
   "metadata": {
    "id": "9cc3b5ba"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/quora_train.csv\")\n",
    "eval_df = pd.read_csv(\"data/quora_eval.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe34f40",
   "metadata": {
    "id": "afe34f40",
    "outputId": "aea117f1-7f44-4587-9c48-6e3d52a55b2b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>375490</td>\n",
       "      <td>375496</td>\n",
       "      <td>506538</td>\n",
       "      <td>506539</td>\n",
       "      <td>What is new and noteworthy in the Marketing fi...</td>\n",
       "      <td>Are there any certifications and learnings onl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>195357</td>\n",
       "      <td>195363</td>\n",
       "      <td>295784</td>\n",
       "      <td>236283</td>\n",
       "      <td>Do girls with large breasts avoid hugs?</td>\n",
       "      <td>What are some bad things about having large br...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>232791</td>\n",
       "      <td>232797</td>\n",
       "      <td>240315</td>\n",
       "      <td>342882</td>\n",
       "      <td>What does it mean when you dream of getting sh...</td>\n",
       "      <td>What does it mean to be shot in the back of th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>148747</td>\n",
       "      <td>148753</td>\n",
       "      <td>234468</td>\n",
       "      <td>234469</td>\n",
       "      <td>What are some examples of a flat character in ...</td>\n",
       "      <td>What are some examples of flat characters in l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>371036</td>\n",
       "      <td>371042</td>\n",
       "      <td>104329</td>\n",
       "      <td>474854</td>\n",
       "      <td>What do you do on weekends?</td>\n",
       "      <td>What do you do during weekends?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      id    qid1    qid2  \\\n",
       "0      375490  375496  506538  506539   \n",
       "1      195357  195363  295784  236283   \n",
       "2      232791  232797  240315  342882   \n",
       "3      148747  148753  234468  234469   \n",
       "4      371036  371042  104329  474854   \n",
       "\n",
       "                                           question1  \\\n",
       "0  What is new and noteworthy in the Marketing fi...   \n",
       "1            Do girls with large breasts avoid hugs?   \n",
       "2  What does it mean when you dream of getting sh...   \n",
       "3  What are some examples of a flat character in ...   \n",
       "4                        What do you do on weekends?   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  Are there any certifications and learnings onl...             0  \n",
       "1  What are some bad things about having large br...             0  \n",
       "2  What does it mean to be shot in the back of th...             0  \n",
       "3  What are some examples of flat characters in l...             1  \n",
       "4                    What do you do during weekends?             1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c8d6da",
   "metadata": {
    "id": "90c8d6da",
    "outputId": "995de942-2aa1-4d1e-ab88-b0fadc834c13"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/anaconda/envs/summenv38/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2212: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/anaconda/envs/summenv38/lib/python3.8/site-packages/transformers/models/t5/tokenization_t5.py:190: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val dataset:  40429\n",
      "paraphrase: What are some examples of a flat character in a piece of literature?</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "What are some examples of flat characters in literature?</s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "{'data_dir': 'data', 'output_dir': 't5_paraphrase', 'model_name_or_path': 't5-small', 'tokenizer_name_or_path': 't5-small', 'max_seq_length': 64, 'learning_rate': 0.0003, 'weight_decay': 0.0, 'adam_epsilon': 1e-08, 'warmup_steps': 0, 'train_batch_size': 64, 'eval_batch_size': 64, 'num_train_epochs': 2, 'gradient_accumulation_steps': 2, 'n_gpu': 1, 'early_stop_callback': False, 'fp_16': False, 'opt_level': 'O1', 'max_grad_norm': 1.0, 'seed': 42, 'report_to': 'wandb'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/summenv38/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:446: UserWarning: Checkpoint directory t5_paraphrase exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    }
   ],
   "source": [
    "# setup model training\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "\n",
    "class T5FineTuner(pl.LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super(T5FineTuner, self).__init__()\n",
    "        #print(hparams)\n",
    "        #self.hparams = hparams\n",
    "        \n",
    "        self.hparams.update(vars(hparams))\n",
    "        \n",
    "        #for key in hparams.keys():\n",
    "        #    help_hparams[key]=hparams[key]\n",
    "        #self.hparams = argparse.Namespace(**help_hparams)\n",
    "        \n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(hparams.model_name_or_path)\n",
    "        self.tokenizer = T5Tokenizer.from_pretrained(hparams.tokenizer_name_or_path)\n",
    "\n",
    "    def is_logger(self):\n",
    "        return self.trainer.global_rank <= 0\n",
    "\n",
    "    def forward(\n",
    "            self, input_ids, attention_mask=None, decoder_input_ids=None, decoder_attention_mask=None, labels=None\n",
    "    ):\n",
    "        return self.model(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            decoder_input_ids=decoder_input_ids,\n",
    "            decoder_attention_mask=decoder_attention_mask,\n",
    "            labels=labels,\n",
    "        )\n",
    "\n",
    "    def _step(self, batch):\n",
    "        labels = batch[\"target_ids\"]\n",
    "        labels[labels[:, :] == self.tokenizer.pad_token_id] = -100\n",
    "\n",
    "        outputs = self(\n",
    "            input_ids=batch[\"source_ids\"],\n",
    "            attention_mask=batch[\"source_mask\"],\n",
    "            labels=labels,\n",
    "            decoder_attention_mask=batch['target_mask']\n",
    "        )\n",
    "\n",
    "        loss = outputs[0]\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self._step(batch)\n",
    "\n",
    "        tensorboard_logs = {\"train_loss\": loss}\n",
    "        return {\"loss\": loss, \"log\": tensorboard_logs}\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        avg_train_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n",
    "        tensorboard_logs = {\"avg_train_loss\": avg_train_loss}\n",
    "        #return {\"avg_train_loss\": avg_train_loss, \"log\": tensorboard_logs, 'progress_bar': tensorboard_logs}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self._step(batch)\n",
    "        return {\"val_loss\": loss}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        tensorboard_logs = {\"val_loss\": avg_loss}\n",
    "        return {\"avg_val_loss\": avg_loss, \"log\": tensorboard_logs, 'progress_bar': tensorboard_logs}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"Prepare optimizer and schedule (linear warmup and decay)\"\n",
    "\n",
    "        model = self.model\n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": self.hparams.weight_decay,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "        optimizer = AdamW(optimizer_grouped_parameters, lr=self.hparams.learning_rate, eps=self.hparams.adam_epsilon)\n",
    "        self.opt = optimizer\n",
    "        return [optimizer]\n",
    "\n",
    "    # def optimizer_step(self, epoch, batch_idx, optimizer, optimizer_idx, second_order_closure=None):\n",
    "    #     # if self.trainer.use_tpu:\n",
    "    #     #     xm.optimizer_step(optimizer)\n",
    "    #     # else:\n",
    "    #         # optimizer.step()\n",
    "    #     optimizer.step()\n",
    "    #     optimizer.zero_grad()\n",
    "    #     self.lr_scheduler.step()\n",
    "\n",
    "    def optimizer_step(self,\n",
    "                     epoch=None,\n",
    "                     batch_idx=None,\n",
    "                     optimizer=None,\n",
    "                     optimizer_idx=None,\n",
    "                     optimizer_closure=None,\n",
    "                     on_tpu=None,\n",
    "                     using_native_amp=None,\n",
    "                     using_lbfgs=None):\n",
    "\n",
    "        optimizer.step() # remove 'closure=optimizer_closure' here\n",
    "        optimizer.zero_grad()\n",
    "        self.lr_scheduler.step()\n",
    "\n",
    "\n",
    "    def get_tqdm_dict(self):\n",
    "        tqdm_dict = {\"loss\": \"{:.3f}\".format(self.trainer.avg_loss), \"lr\": self.lr_scheduler.get_last_lr()[-1]}\n",
    "\n",
    "        return tqdm_dict\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_dataset = get_dataset(tokenizer=self.tokenizer, type_path=\"quora_train\", args=self.hparams)\n",
    "        dataloader = DataLoader(train_dataset, batch_size=self.hparams.train_batch_size, drop_last=True, shuffle=True,\n",
    "                                num_workers=4)\n",
    "        t_total = (\n",
    "                (len(dataloader.dataset) // (self.hparams.train_batch_size * max(1, self.hparams.n_gpu)))\n",
    "                // self.hparams.gradient_accumulation_steps\n",
    "                * float(self.hparams.num_train_epochs)\n",
    "        )\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            self.opt, num_warmup_steps=self.hparams.warmup_steps, num_training_steps=t_total\n",
    "        )\n",
    "        self.lr_scheduler = scheduler\n",
    "        return dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val_dataset = get_dataset(tokenizer=self.tokenizer, type_path=\"quora_eval\", args=self.hparams)\n",
    "        return DataLoader(val_dataset, batch_size=self.hparams.eval_batch_size, num_workers=4)\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class LoggingCallback(pl.Callback):\n",
    "    def on_validation_end(self, trainer, pl_module):\n",
    "        logger.info(\"***** Validation results *****\")\n",
    "        if pl_module.is_logger():\n",
    "            metrics = trainer.callback_metrics\n",
    "      # Log results\n",
    "            for key in sorted(metrics):\n",
    "                if key not in [\"log\", \"progress_bar\"]:\n",
    "                    logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
    "\n",
    "    def on_test_end(self, trainer, pl_module):\n",
    "        logger.info(\"***** Test results *****\")\n",
    "\n",
    "        if pl_module.is_logger():\n",
    "            metrics = trainer.callback_metrics\n",
    "\n",
    "      # Log and save results to file\n",
    "            output_test_results_file = os.path.join(pl_module.hparams.output_dir, \"test_results.txt\")\n",
    "            with open(output_test_results_file, \"w\") as writer:\n",
    "                for key in sorted(metrics):\n",
    "                    if key not in [\"log\", \"progress_bar\"]:\n",
    "                        logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
    "                        writer.write(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
    "\n",
    "\n",
    "\n",
    "args_dict = dict(\n",
    "    data_dir=\"\", # path for data files\n",
    "    output_dir=\"\", # path to save the checkpoints\n",
    "    model_name_or_path='t5-small',\n",
    "    tokenizer_name_or_path='t5-small',\n",
    "    max_seq_length=64,\n",
    "    learning_rate=3e-4,\n",
    "    weight_decay=0.0,\n",
    "    adam_epsilon=1e-8,\n",
    "    warmup_steps=0,\n",
    "    train_batch_size=64,\n",
    "    eval_batch_size=64,\n",
    "    num_train_epochs=2,\n",
    "    gradient_accumulation_steps=2,\n",
    "    n_gpu=1,\n",
    "    early_stop_callback=False,\n",
    "    fp_16=False, # if you want to enable 16-bit training then install apex and set this to true\n",
    "    opt_level='O1', # you can find out more on optimisation levels here https://nvidia.github.io/apex/amp.html#opt-levels-and-properties\n",
    "    max_grad_norm=1.0, # if you enable 16-bit training then set this to a sensible value, 0.5 is a good default\n",
    "    seed=42,\n",
    "    report_to=\"wandb\",\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "\n",
    "\n",
    "\n",
    "class ParaphraseDataset(Dataset):\n",
    "    def __init__(self, tokenizer, data_dir, type_path, max_len=64):\n",
    "        self.path = os.path.join(data_dir, type_path + '.csv')\n",
    "\n",
    "        self.source_column = \"question1\"\n",
    "        self.target_column = \"question2\"\n",
    "        self.data = pd.read_csv(self.path)\n",
    "\n",
    "        #data_help = pd.read_csv(self.path)\n",
    "\n",
    "        #self.data = data_help.loc[:20] \n",
    "\n",
    "        \n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = tokenizer\n",
    "        self.inputs = []\n",
    "        self.targets = []\n",
    "\n",
    "        self._build()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        source_ids = self.inputs[index][\"input_ids\"].squeeze()\n",
    "        target_ids = self.targets[index][\"input_ids\"].squeeze()\n",
    "\n",
    "        src_mask = self.inputs[index][\"attention_mask\"].squeeze()  # might need to squeeze\n",
    "        target_mask = self.targets[index][\"attention_mask\"].squeeze()  # might need to squeeze\n",
    "\n",
    "        return {\"source_ids\": source_ids, \"source_mask\": src_mask, \"target_ids\": target_ids, \"target_mask\": target_mask}\n",
    "\n",
    "    def _build(self):\n",
    "        for idx in range(len(self.data)):\n",
    "            input_, target = self.data.loc[idx, self.source_column], self.data.loc[idx, self.target_column]\n",
    "\n",
    "            input_ = \"paraphrase: \"+ str(input_) + ' </s>'\n",
    "            target = str(target) + \" </s>\"\n",
    "\n",
    "            # tokenize inputs\n",
    "            tokenized_inputs = self.tokenizer.batch_encode_plus(\n",
    "                [input_], max_length=self.max_len, pad_to_max_length=True, return_tensors=\"pt\"\n",
    "            )\n",
    "            # tokenize targets\n",
    "            tokenized_targets = self.tokenizer.batch_encode_plus(\n",
    "                [target], max_length=self.max_len, pad_to_max_length=True, return_tensors=\"pt\"\n",
    "            )\n",
    "\n",
    "            self.inputs.append(tokenized_inputs)\n",
    "            self.targets.append(tokenized_targets)\n",
    "\n",
    "\n",
    "\n",
    "dataset = ParaphraseDataset(tokenizer, 'data', 'quora_eval', 64)\n",
    "print(\"Val dataset: \",len(dataset))\n",
    "\n",
    "data = dataset[3]\n",
    "print(tokenizer.decode(data['source_ids']))\n",
    "print(tokenizer.decode(data['target_ids']))\n",
    "\n",
    "if not os.path.exists('t5_paraphrase'):\n",
    "    os.makedirs('t5_paraphrase')\n",
    "\n",
    "args_dict.update({'data_dir': 'data', 'output_dir': 't5_paraphrase', 'num_train_epochs':2,'max_seq_length':64})\n",
    "args = argparse.Namespace(**args_dict)\n",
    "print(args_dict)\n",
    "\n",
    "\n",
    "\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    dirpath=args.output_dir, monitor=\"val_loss\", mode=\"min\", save_top_k=5\n",
    "    #filepath=args.output_dir, prefix=\"checkpoint\", monitor=\"val_loss\", mode=\"min\", save_top_k=5\n",
    ")\n",
    "\n",
    "train_params = dict(\n",
    "    accumulate_grad_batches=args.gradient_accumulation_steps,\n",
    "    gpus=args.n_gpu,\n",
    "    max_epochs=args.num_train_epochs,\n",
    "    #early_stop_callback=False,\n",
    "    precision= 16 if args.fp_16 else 32,\n",
    "    amp_level=args.opt_level,\n",
    "    gradient_clip_val=args.max_grad_norm,\n",
    "    # checkpoint_callback=checkpoint_callback,\n",
    "    callbacks=[LoggingCallback()],\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "def get_dataset(tokenizer, type_path, args):\n",
    "    return ParaphraseDataset(tokenizer=tokenizer, data_dir=args.data_dir, type_path=type_path,  max_len=args.max_seq_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d802e46",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "",
      "1ce02b14ce49476ea70a82e794faf83e"
     ]
    },
    "id": "0d802e46",
    "outputId": "ff14e25a-5955-472a-8bdc-683ff351c212"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "/anaconda/envs/summenv38/lib/python3.8/site-packages/pytorch_lightning/trainer/configuration_validator.py:85: UserWarning: When using `Trainer(accumulate_grad_batches != 1)` and overriding`LightningModule.optimizer_{step,zero_grad}`, the hooks will not be called on every batch(rather, they are called on every optimization step).\n",
      "  rank_zero_warn(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Training model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name  | Type                       | Params\n",
      "-----------------------------------------------------\n",
      "0 | model | T5ForConditionalGeneration | 60.5 M\n",
      "-----------------------------------------------------\n",
      "60.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "60.5 M    Total params\n",
      "242.026   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ce02b14ce49476ea70a82e794faf83e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/summenv38/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:405: LightningDeprecationWarning: One of the returned values {'log'} has a `grad_fn`. We will detach it automatically but this behaviour will change in v1.6. Please detach it manually: `return {'loss': ..., 'something': something.detach()}`\n",
      "  warning_cache.deprecation(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training finished\n",
      "Saving model\n",
      "Saved model\n"
     ]
    }
   ],
   "source": [
    "print (\"Initialize model\")\n",
    "model = T5FineTuner(args)\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(**train_params)\n",
    "\n",
    "\n",
    "print (\" Training model\")\n",
    "trainer.fit(model)\n",
    "\n",
    "print (\"training finished\")\n",
    "\n",
    "\n",
    "print (\"Saving model\")\n",
    "model.model.save_pretrained('t5_paraphrase_quora')\n",
    "\n",
    "print (\"Saved model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d99fbaa",
   "metadata": {
    "id": "1d99fbaa",
    "outputId": "07faa496-3e1b-4533-b99c-3f674565a343"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t\n"
     ]
    }
   ],
   "source": [
    "print(\"t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2e0fb0",
   "metadata": {
    "id": "de2e0fb0"
   },
   "outputs": [],
   "source": [
    "model_final = T5ForConditionalGeneration.from_pretrained('t5_paraphrase_quora')\n",
    "tokenizer = T5Tokenizer.from_pretrained(args.tokenizer_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa61a60",
   "metadata": {
    "id": "0aa61a60",
    "outputId": "0e3017a7-525a-4b2f-ebab-72d084684839"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device  cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print (\"device \",device)\n",
    "model = model_final.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cdc4b3",
   "metadata": {
    "id": "07cdc4b3",
    "outputId": "127ef357-83cc-45b3-f178-34ecbdf705a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Sentence::\n",
      "What is the best possible approach to learn aeronautical engineering?\n",
      "\n",
      "\n",
      "Paraphrased Sentence: \n",
      "0: Is there a way to learn aeronautical engineering?\n",
      "1: Which is the best method to learn aeronautical engineering?\n",
      "2: What is the best way to learn aeronautical engineering?\n",
      "3: What is the best way to learn aeronautic engineering in real-world life?\n",
      "4: What are some good options for studying aeronautical engineering?\n"
     ]
    }
   ],
   "source": [
    "#sentence = \"She was one of them, really, blithe and girlish in her manner and her tastes—video games, Harry Potter, the baffling pop music they listened to.\"\n",
    "#sentence = \"What are the ingredients required to bake a perfect cake?\"\n",
    "sentence = \"What is the best possible approach to learn aeronautical engineering?\"\n",
    "#sentence = \"Do apples taste better than oranges in general?\"\n",
    "\n",
    "\n",
    "text =  \"paraphase:\" + sentence + \" </s>\"\n",
    "\n",
    "\n",
    "max_len = 64\n",
    "\n",
    "encoding = tokenizer.encode_plus(text,pad_to_max_length=True, return_tensors=\"pt\")\n",
    "input_ids, attention_masks = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)\n",
    "\n",
    "\n",
    "# set top_k = 50 and set top_p = 0.95 and num_return_sequences = 3\n",
    "beam_outputs = model.generate(\n",
    "    input_ids=input_ids, attention_mask=attention_masks,\n",
    "    do_sample=True,\n",
    "    max_length=64,\n",
    "    top_k=120,\n",
    "    top_p=0.98,\n",
    "    early_stopping=True,\n",
    "    num_return_sequences=5\n",
    ")\n",
    "\n",
    "\n",
    "print (\"\\nOriginal Sentence::\")\n",
    "print (sentence)\n",
    "print (\"\\n\")\n",
    "print (\"Paraphrased Sentence: \")\n",
    "final_outputs =[]\n",
    "for beam_output in beam_outputs:\n",
    "    sent = tokenizer.decode(beam_output, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
    "    if sent.lower() != sentence.lower() and sent not in final_outputs:\n",
    "        final_outputs.append(sent)\n",
    "\n",
    "for i, final_output in enumerate(final_outputs):\n",
    "    print(\"{}: {}\".format(i, final_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a7f50f",
   "metadata": {
    "id": "33a7f50f"
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('data/quora_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be7a62f",
   "metadata": {
    "id": "8be7a62f",
    "outputId": "4a176ea1-7322-4c8e-9cd3-314310e24c6e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>149643</td>\n",
       "      <td>149649</td>\n",
       "      <td>117395</td>\n",
       "      <td>58546</td>\n",
       "      <td>What hotel in Mysore would be safe for unmarri...</td>\n",
       "      <td>What hotel in Kochi would be safe for unmarrie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>274741</td>\n",
       "      <td>274747</td>\n",
       "      <td>303590</td>\n",
       "      <td>210228</td>\n",
       "      <td>What are the typical physical traits of an att...</td>\n",
       "      <td>Can a girl rule a boy by using her attractive ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>142010</td>\n",
       "      <td>142016</td>\n",
       "      <td>225316</td>\n",
       "      <td>225317</td>\n",
       "      <td>What some examples of workplace risks and haza...</td>\n",
       "      <td>What are workplace risks and hazards? What are...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>162575</td>\n",
       "      <td>162581</td>\n",
       "      <td>253079</td>\n",
       "      <td>131365</td>\n",
       "      <td>In what scenario would the U S and China use m...</td>\n",
       "      <td>How would a war between the US and China play ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>401575</td>\n",
       "      <td>401581</td>\n",
       "      <td>49318</td>\n",
       "      <td>162037</td>\n",
       "      <td>How do you self publish a book?</td>\n",
       "      <td>What is the process of publishing a book?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40423</th>\n",
       "      <td>26034</td>\n",
       "      <td>26040</td>\n",
       "      <td>48504</td>\n",
       "      <td>48505</td>\n",
       "      <td>Which actors were screen-tested for the role o...</td>\n",
       "      <td>The Dark Knight Rises (2012 movie): The same d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40424</th>\n",
       "      <td>292713</td>\n",
       "      <td>292719</td>\n",
       "      <td>414366</td>\n",
       "      <td>93356</td>\n",
       "      <td>Psychology says that if you dream about someon...</td>\n",
       "      <td>What does it mean when you dream about someone...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40425</th>\n",
       "      <td>126055</td>\n",
       "      <td>126061</td>\n",
       "      <td>203263</td>\n",
       "      <td>203264</td>\n",
       "      <td>Certain people of reserved category of college...</td>\n",
       "      <td>Fedora 24 how to prevent celestia from crashing?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40426</th>\n",
       "      <td>159769</td>\n",
       "      <td>159775</td>\n",
       "      <td>34003</td>\n",
       "      <td>249353</td>\n",
       "      <td>Which is the best question you've read on Quora?</td>\n",
       "      <td>What is the best question on Quora ever?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40427</th>\n",
       "      <td>98272</td>\n",
       "      <td>98278</td>\n",
       "      <td>149375</td>\n",
       "      <td>157481</td>\n",
       "      <td>Can I grow height after 19 years?</td>\n",
       "      <td>Is it possible to increase your height after 19?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40428 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0      id    qid1    qid2  \\\n",
       "0          149643  149649  117395   58546   \n",
       "1          274741  274747  303590  210228   \n",
       "2          142010  142016  225316  225317   \n",
       "3          162575  162581  253079  131365   \n",
       "4          401575  401581   49318  162037   \n",
       "...           ...     ...     ...     ...   \n",
       "40423       26034   26040   48504   48505   \n",
       "40424      292713  292719  414366   93356   \n",
       "40425      126055  126061  203263  203264   \n",
       "40426      159769  159775   34003  249353   \n",
       "40427       98272   98278  149375  157481   \n",
       "\n",
       "                                               question1  \\\n",
       "0      What hotel in Mysore would be safe for unmarri...   \n",
       "1      What are the typical physical traits of an att...   \n",
       "2      What some examples of workplace risks and haza...   \n",
       "3      In what scenario would the U S and China use m...   \n",
       "4                        How do you self publish a book?   \n",
       "...                                                  ...   \n",
       "40423  Which actors were screen-tested for the role o...   \n",
       "40424  Psychology says that if you dream about someon...   \n",
       "40425  Certain people of reserved category of college...   \n",
       "40426   Which is the best question you've read on Quora?   \n",
       "40427                  Can I grow height after 19 years?   \n",
       "\n",
       "                                               question2  is_duplicate  \n",
       "0      What hotel in Kochi would be safe for unmarrie...             0  \n",
       "1      Can a girl rule a boy by using her attractive ...             0  \n",
       "2      What are workplace risks and hazards? What are...             1  \n",
       "3      How would a war between the US and China play ...             0  \n",
       "4              What is the process of publishing a book?             1  \n",
       "...                                                  ...           ...  \n",
       "40423  The Dark Knight Rises (2012 movie): The same d...             0  \n",
       "40424  What does it mean when you dream about someone...             0  \n",
       "40425   Fedora 24 how to prevent celestia from crashing?             0  \n",
       "40426           What is the best question on Quora ever?             1  \n",
       "40427   Is it possible to increase your height after 19?             1  \n",
       "\n",
       "[40428 rows x 7 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a1c0df",
   "metadata": {
    "id": "03a1c0df"
   },
   "outputs": [],
   "source": [
    "df_test_slice = df_test[0:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4295d4",
   "metadata": {
    "id": "7b4295d4"
   },
   "outputs": [],
   "source": [
    "def testing(sentence):\n",
    "\n",
    "    \n",
    "    text =  \"paraphrase:\" + str(sentence) + \" </s>\"\n",
    "\n",
    "    max_len = 64\n",
    "\n",
    "    encoding = tokenizer.encode_plus(text,pad_to_max_length=True, return_tensors=\"pt\")\n",
    "    input_ids, attention_masks = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)\n",
    "\n",
    "\n",
    "    # set top_k = 50 and set top_p = 0.95 and num_return_sequences = 3\n",
    "    beam_outputs = model.generate(\n",
    "        input_ids=input_ids, attention_mask=attention_masks,\n",
    "        do_sample=True,\n",
    "        max_length=64,\n",
    "        top_k=120,\n",
    "        top_p=0.98,\n",
    "        early_stopping=True,\n",
    "        num_return_sequences=5\n",
    "    )\n",
    "    \n",
    "\n",
    "    final_outputs =[]\n",
    "    for beam_output in beam_outputs:\n",
    "        sent = tokenizer.decode(beam_output, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
    "        if sent.lower() != sentence.lower() and sent not in final_outputs:\n",
    "            final_outputs.append(sent)\n",
    "\n",
    "    #for i, final_output in enumerate(final_outputs):\n",
    "    #   print(\"{}: {}\".format(i, final_output))\n",
    "    #print(final_outputs)\n",
    "\n",
    "    if not final_outputs:\n",
    "        final_outputs= [\"\"]\n",
    "    \n",
    "    return final_outputs[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa42211",
   "metadata": {
    "id": "3fa42211",
    "outputId": "e60d2182-0a74-4e7e-c544-710ddfc3e913"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>149643</td>\n",
       "      <td>149649</td>\n",
       "      <td>117395</td>\n",
       "      <td>58546</td>\n",
       "      <td>What hotel in Mysore would be safe for unmarri...</td>\n",
       "      <td>What hotel in Kochi would be safe for unmarrie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>274741</td>\n",
       "      <td>274747</td>\n",
       "      <td>303590</td>\n",
       "      <td>210228</td>\n",
       "      <td>What are the typical physical traits of an att...</td>\n",
       "      <td>Can a girl rule a boy by using her attractive ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>142010</td>\n",
       "      <td>142016</td>\n",
       "      <td>225316</td>\n",
       "      <td>225317</td>\n",
       "      <td>What some examples of workplace risks and haza...</td>\n",
       "      <td>What are workplace risks and hazards? What are...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>162575</td>\n",
       "      <td>162581</td>\n",
       "      <td>253079</td>\n",
       "      <td>131365</td>\n",
       "      <td>In what scenario would the U S and China use m...</td>\n",
       "      <td>How would a war between the US and China play ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>401575</td>\n",
       "      <td>401581</td>\n",
       "      <td>49318</td>\n",
       "      <td>162037</td>\n",
       "      <td>How do you self publish a book?</td>\n",
       "      <td>What is the process of publishing a book?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40423</th>\n",
       "      <td>26034</td>\n",
       "      <td>26040</td>\n",
       "      <td>48504</td>\n",
       "      <td>48505</td>\n",
       "      <td>Which actors were screen-tested for the role o...</td>\n",
       "      <td>The Dark Knight Rises (2012 movie): The same d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40424</th>\n",
       "      <td>292713</td>\n",
       "      <td>292719</td>\n",
       "      <td>414366</td>\n",
       "      <td>93356</td>\n",
       "      <td>Psychology says that if you dream about someon...</td>\n",
       "      <td>What does it mean when you dream about someone...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40425</th>\n",
       "      <td>126055</td>\n",
       "      <td>126061</td>\n",
       "      <td>203263</td>\n",
       "      <td>203264</td>\n",
       "      <td>Certain people of reserved category of college...</td>\n",
       "      <td>Fedora 24 how to prevent celestia from crashing?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40426</th>\n",
       "      <td>159769</td>\n",
       "      <td>159775</td>\n",
       "      <td>34003</td>\n",
       "      <td>249353</td>\n",
       "      <td>Which is the best question you've read on Quora?</td>\n",
       "      <td>What is the best question on Quora ever?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40427</th>\n",
       "      <td>98272</td>\n",
       "      <td>98278</td>\n",
       "      <td>149375</td>\n",
       "      <td>157481</td>\n",
       "      <td>Can I grow height after 19 years?</td>\n",
       "      <td>Is it possible to increase your height after 19?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40428 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0      id    qid1    qid2  \\\n",
       "0          149643  149649  117395   58546   \n",
       "1          274741  274747  303590  210228   \n",
       "2          142010  142016  225316  225317   \n",
       "3          162575  162581  253079  131365   \n",
       "4          401575  401581   49318  162037   \n",
       "...           ...     ...     ...     ...   \n",
       "40423       26034   26040   48504   48505   \n",
       "40424      292713  292719  414366   93356   \n",
       "40425      126055  126061  203263  203264   \n",
       "40426      159769  159775   34003  249353   \n",
       "40427       98272   98278  149375  157481   \n",
       "\n",
       "                                               question1  \\\n",
       "0      What hotel in Mysore would be safe for unmarri...   \n",
       "1      What are the typical physical traits of an att...   \n",
       "2      What some examples of workplace risks and haza...   \n",
       "3      In what scenario would the U S and China use m...   \n",
       "4                        How do you self publish a book?   \n",
       "...                                                  ...   \n",
       "40423  Which actors were screen-tested for the role o...   \n",
       "40424  Psychology says that if you dream about someon...   \n",
       "40425  Certain people of reserved category of college...   \n",
       "40426   Which is the best question you've read on Quora?   \n",
       "40427                  Can I grow height after 19 years?   \n",
       "\n",
       "                                               question2  is_duplicate  \n",
       "0      What hotel in Kochi would be safe for unmarrie...             0  \n",
       "1      Can a girl rule a boy by using her attractive ...             0  \n",
       "2      What are workplace risks and hazards? What are...             1  \n",
       "3      How would a war between the US and China play ...             0  \n",
       "4              What is the process of publishing a book?             1  \n",
       "...                                                  ...           ...  \n",
       "40423  The Dark Knight Rises (2012 movie): The same d...             0  \n",
       "40424  What does it mean when you dream about someone...             0  \n",
       "40425   Fedora 24 how to prevent celestia from crashing?             0  \n",
       "40426           What is the best question on Quora ever?             1  \n",
       "40427   Is it possible to increase your height after 19?             1  \n",
       "\n",
       "[40428 rows x 7 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f53fc918",
   "metadata": {
    "id": "f53fc918",
    "outputId": "c42e3dbc-9b73-4aaa-f772-6423dd06f8c3"
   },
   "outputs": [],
   "source": [
    "df_test['prediction'] = df_test.question1.apply(lambda x: testing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a51bfc",
   "metadata": {
    "id": "32a51bfc",
    "outputId": "695d1d1e-b7f8-467b-abcc-ef6b16afe0f9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>149643</td>\n",
       "      <td>149649</td>\n",
       "      <td>117395</td>\n",
       "      <td>58546</td>\n",
       "      <td>What hotel in Mysore would be safe for unmarri...</td>\n",
       "      <td>What hotel in Kochi would be safe for unmarrie...</td>\n",
       "      <td>0</td>\n",
       "      <td>What hotel in San Francisco would be safe for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>274741</td>\n",
       "      <td>274747</td>\n",
       "      <td>303590</td>\n",
       "      <td>210228</td>\n",
       "      <td>What are the typical physical traits of an att...</td>\n",
       "      <td>Can a girl rule a boy by using her attractive ...</td>\n",
       "      <td>0</td>\n",
       "      <td>What are the typical physical traits of a keen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>142010</td>\n",
       "      <td>142016</td>\n",
       "      <td>225316</td>\n",
       "      <td>225317</td>\n",
       "      <td>What some examples of workplace risks and haza...</td>\n",
       "      <td>What are workplace risks and hazards? What are...</td>\n",
       "      <td>1</td>\n",
       "      <td>What are some examples of workplace risk or ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>162575</td>\n",
       "      <td>162581</td>\n",
       "      <td>253079</td>\n",
       "      <td>131365</td>\n",
       "      <td>In what scenario would the U S and China use m...</td>\n",
       "      <td>How would a war between the US and China play ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Are China able to use their military force aga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>401575</td>\n",
       "      <td>401581</td>\n",
       "      <td>49318</td>\n",
       "      <td>162037</td>\n",
       "      <td>How do you self publish a book?</td>\n",
       "      <td>What is the process of publishing a book?</td>\n",
       "      <td>1</td>\n",
       "      <td>How to self publish a book?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>5099</td>\n",
       "      <td>5105</td>\n",
       "      <td>10059</td>\n",
       "      <td>10060</td>\n",
       "      <td>What political orientation does India follow?</td>\n",
       "      <td>Which political orientation does India follow?</td>\n",
       "      <td>1</td>\n",
       "      <td>What is your biggest objective in India?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>93244</td>\n",
       "      <td>93250</td>\n",
       "      <td>94629</td>\n",
       "      <td>155954</td>\n",
       "      <td>I'm in college how do I start my own hedge fund?</td>\n",
       "      <td>How do you start your own hedge fund? How do y...</td>\n",
       "      <td>1</td>\n",
       "      <td>Why do hedge funds work? Why are banks so used...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>300399</td>\n",
       "      <td>300405</td>\n",
       "      <td>423188</td>\n",
       "      <td>91511</td>\n",
       "      <td>How do I retrieve a WhatsApp message from some...</td>\n",
       "      <td>How can I hack someone else's WhatsApp account...</td>\n",
       "      <td>0</td>\n",
       "      <td>How can I retrieve a WhatsApp message from the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>57165</td>\n",
       "      <td>57171</td>\n",
       "      <td>100502</td>\n",
       "      <td>100503</td>\n",
       "      <td>Can Plan B cause an ectopic pregnancy? Why or ...</td>\n",
       "      <td>Can you get your period with an ectopic pregna...</td>\n",
       "      <td>0</td>\n",
       "      <td>Why does CPA cause the fetal ectopic pregnancy?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>264620</td>\n",
       "      <td>264626</td>\n",
       "      <td>152754</td>\n",
       "      <td>10514</td>\n",
       "      <td>Which is your favorite horror movie?</td>\n",
       "      <td>What are your 10 favorite horror movies?</td>\n",
       "      <td>1</td>\n",
       "      <td>What is your favorite horror movie?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0      id    qid1    qid2  \\\n",
       "0         149643  149649  117395   58546   \n",
       "1         274741  274747  303590  210228   \n",
       "2         142010  142016  225316  225317   \n",
       "3         162575  162581  253079  131365   \n",
       "4         401575  401581   49318  162037   \n",
       "...          ...     ...     ...     ...   \n",
       "4995        5099    5105   10059   10060   \n",
       "4996       93244   93250   94629  155954   \n",
       "4997      300399  300405  423188   91511   \n",
       "4998       57165   57171  100502  100503   \n",
       "4999      264620  264626  152754   10514   \n",
       "\n",
       "                                              question1  \\\n",
       "0     What hotel in Mysore would be safe for unmarri...   \n",
       "1     What are the typical physical traits of an att...   \n",
       "2     What some examples of workplace risks and haza...   \n",
       "3     In what scenario would the U S and China use m...   \n",
       "4                       How do you self publish a book?   \n",
       "...                                                 ...   \n",
       "4995      What political orientation does India follow?   \n",
       "4996   I'm in college how do I start my own hedge fund?   \n",
       "4997  How do I retrieve a WhatsApp message from some...   \n",
       "4998  Can Plan B cause an ectopic pregnancy? Why or ...   \n",
       "4999               Which is your favorite horror movie?   \n",
       "\n",
       "                                              question2  is_duplicate  \\\n",
       "0     What hotel in Kochi would be safe for unmarrie...             0   \n",
       "1     Can a girl rule a boy by using her attractive ...             0   \n",
       "2     What are workplace risks and hazards? What are...             1   \n",
       "3     How would a war between the US and China play ...             0   \n",
       "4             What is the process of publishing a book?             1   \n",
       "...                                                 ...           ...   \n",
       "4995     Which political orientation does India follow?             1   \n",
       "4996  How do you start your own hedge fund? How do y...             1   \n",
       "4997  How can I hack someone else's WhatsApp account...             0   \n",
       "4998  Can you get your period with an ectopic pregna...             0   \n",
       "4999           What are your 10 favorite horror movies?             1   \n",
       "\n",
       "                                             prediction  \n",
       "0     What hotel in San Francisco would be safe for ...  \n",
       "1     What are the typical physical traits of a keen...  \n",
       "2     What are some examples of workplace risk or ha...  \n",
       "3     Are China able to use their military force aga...  \n",
       "4                           How to self publish a book?  \n",
       "...                                                 ...  \n",
       "4995           What is your biggest objective in India?  \n",
       "4996  Why do hedge funds work? Why are banks so used...  \n",
       "4997  How can I retrieve a WhatsApp message from the...  \n",
       "4998    Why does CPA cause the fetal ectopic pregnancy?  \n",
       "4999                What is your favorite horror movie?  \n",
       "\n",
       "[5000 rows x 8 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4baa98d",
   "metadata": {
    "id": "d4baa98d"
   },
   "outputs": [],
   "source": [
    "df_test_slice.to_csv('data/quora_preds_slice.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Train_Model_Quora.ipynb",
   "provenance": []
  },
  "kernel_info": {
   "name": "azureml_py38_pytorch"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
